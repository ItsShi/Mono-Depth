{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItsShi/Mono-Depth/blob/main/Copy_of_3D_Reconstruction_Pose_Depth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading sample dataset"
      ],
      "metadata": {
        "id": "_-iWGeWmKz67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "ids = ['1Hk38P1sqyCOuOTAmodF0VK6tgGj61qdb']\n",
        "zip_files = ['data.zip']\n",
        "for id, zip_file in zip(ids, zip_files):\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile(zip_file)\n",
        "    if zip_file[-3:] == 'zip':\n",
        "        !unzip -q $zip_file\n",
        "!unzip -q data/Frames_S7.zip -d data/"
      ],
      "metadata": {
        "id": "bGvw-TnnK2ay"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install matplotlib==3.4"
      ],
      "metadata": {
        "id": "VWC4_6eERX-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431dcbb5-15d0-4693-cadb-39c9c0e28cb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 10.3 MB 4.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rAp7ChrmKKo2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import torch\n",
        "\n",
        "class CameraPoseVisualizerSlim:\n",
        "    \"\"\"\n",
        "    Adapted from https://github.com/demul/extrinsic2pyramid\n",
        "    \"\"\"\n",
        "    def __init__(self, xlim=[-5, 15], ylim=[0, 20],zlim=[-5, 15]):\n",
        "        self.fig = plt.figure(figsize=(10, 10), constrained_layout=True)\n",
        "        self.fig.patch.set_alpha(0)\n",
        "\n",
        "        self.subfigs = self.fig.subfigures(nrows=1, ncols=1)\n",
        "\n",
        "        self.ax3d1 = self.subfigs.add_subplot(1, 1, 1, projection='3d', facecolor=\"none\")\n",
        "\n",
        "        self.ax3d1.set_xlim(xlim)\n",
        "        self.ax3d1.set_ylim(ylim)\n",
        "        self.ax3d1.set_zlim(zlim)\n",
        "\n",
        "        self.ax3d1.set_box_aspect(aspect =(xlim[1]-xlim[0],ylim[1]-ylim[0],zlim[1]-zlim[0]))\n",
        "\n",
        "\n",
        "        self.intrinsics = np.eye(3)\n",
        "        self.intrinsics[0, 0] = 237.5\n",
        "        self.intrinsics[0, 2] = 237.5\n",
        "        self.intrinsics[1, 1] = 237.5\n",
        "        self.intrinsics[1, 2] = 237.5\n",
        "\n",
        "\n",
        "    def extrinsic2pyramidAbs(self, extrinsic, color='r', focal_len_scaled=5, aspect_ratio=0.7):\n",
        "        vertex_std = np.array([[0, 0, 0, 1],\n",
        "                               [focal_len_scaled * aspect_ratio, -focal_len_scaled * aspect_ratio, focal_len_scaled, 1],\n",
        "                               [focal_len_scaled * aspect_ratio, focal_len_scaled * aspect_ratio, focal_len_scaled, 1],\n",
        "                               [-focal_len_scaled * aspect_ratio, focal_len_scaled * aspect_ratio, focal_len_scaled, 1],\n",
        "                               [-focal_len_scaled * aspect_ratio, -focal_len_scaled * aspect_ratio, focal_len_scaled, 1]])\n",
        "        vertex_transformed = vertex_std @ extrinsic.T\n",
        "        meshes = [[vertex_transformed[0, :-1], vertex_transformed[1][:-1], vertex_transformed[2, :-1]],\n",
        "                            [vertex_transformed[0, :-1], vertex_transformed[2, :-1], vertex_transformed[3, :-1]],\n",
        "                            [vertex_transformed[0, :-1], vertex_transformed[3, :-1], vertex_transformed[4, :-1]],\n",
        "                            [vertex_transformed[0, :-1], vertex_transformed[4, :-1], vertex_transformed[1, :-1]],\n",
        "                            [vertex_transformed[1, :-1], vertex_transformed[2, :-1], vertex_transformed[3, :-1], vertex_transformed[4, :-1]]]\n",
        "\n",
        "        self.ax3d1.add_collection3d(\n",
        "            Poly3DCollection(meshes, facecolors=color, linewidths=0.3, edgecolors=color, alpha=0.35))\n",
        "\n",
        "\n",
        "    def customize_legend(self):\n",
        "        list_handle = []\n",
        "        list_handle.append(Patch(color='c', label='Ground truth'))\n",
        "        list_handle.append(Patch(color='y', label='Prediction'))\n",
        "\n",
        "        self.ax3d2.legend(loc='upper left', handles=list_handle)\n",
        "\n",
        "\n",
        "    def show(self, name='deleteme'):\n",
        "        plt.savefig(name + '.png', bbox_inches='tight',pad_inches=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from skimage.transform import resize as imresize\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#from camera_visualizer import CameraPoseVisualizerSlim\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import collections\n",
        "from PIL import Image\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "\n",
        "def set_id_grid(depth):\n",
        "    b, h, w = depth.size()\n",
        "    i_range = torch.arange(0, h).view(1, h, 1).expand(\n",
        "        1, h, w).type_as(depth)  # [1, H, W]\n",
        "    j_range = torch.arange(0, w).view(1, 1, w).expand(\n",
        "        1, h, w).type_as(depth)  # [1, H, W]\n",
        "    ones = torch.ones(1, h, w).type_as(depth)\n",
        "    return torch.stack((j_range, i_range, ones), dim=1)  # [1, 3, H, W]\n",
        "\n",
        "def pixel2cam(depth, intrinsics_inv):\n",
        "    b, h, w = depth.size()\n",
        "    pixel_coords = set_id_grid(depth)\n",
        "    current_pixel_coords = pixel_coords[:, :, :h, :w].expand(\n",
        "        b, 3, h, w).reshape(b, 3, -1)  # [B, 3, H*W]\n",
        "    cam_coords = (intrinsics_inv @ current_pixel_coords).reshape(b, 3, h, w)\n",
        "    return cam_coords * depth.unsqueeze(1)\n",
        "\n",
        "def plot_growing_cloud(datasetname, scene, data_root):\n",
        "    locations = []\n",
        "    rotations = []\n",
        "    loc_reader = open(data_root +'SavedPosition_' + datasetname + scene + '.txt', 'r')\n",
        "    rot_reader = open(data_root +'SavedRotationQuaternion_' + datasetname + scene + '.txt',\n",
        "                      'r')\n",
        "    for line in loc_reader:\n",
        "        locations.append(list(map(float, line.split())))\n",
        "    loc_reader.close\n",
        "\n",
        "    for line in rot_reader:\n",
        "        rotations.append(list(map(float, line.split())))\n",
        "    rot_reader.close\n",
        "\n",
        "    locations = np.array(locations)  # in cm\n",
        "    rotations = np.array(rotations)\n",
        "    poses = np.concatenate([locations, rotations], 1)\n",
        "\n",
        "    r = R.from_quat(rotations).as_matrix()\n",
        "\n",
        "    TM = np.eye(4)\n",
        "    TM[1, 1] = -1\n",
        "\n",
        "    poses_mat = []\n",
        "    for i in range(locations.shape[0]):\n",
        "        ri = r[i]  # np.linalg.inv(r[0])\n",
        "        Pi = np.concatenate((ri, locations[i].reshape((3, 1))), 1)\n",
        "        Pi = np.concatenate((Pi, np.array([0.0, 0.0, 0.0, 1.0]).reshape((1, 4))), 0)\n",
        "        Pi_left = TM @ Pi @ TM\n",
        "        poses_mat.append(Pi_left)\n",
        "\n",
        "    visualizer = CameraPoseVisualizerSlim([np.min(np.array(poses_mat)[:,0,-1]), np.max(np.array(poses_mat)[:,0,-1])],\n",
        "                                          [np.min(np.array(poses_mat)[:,1,-1]), np.max(np.array(poses_mat)[:,1,-1])],\n",
        "                                          [np.min(np.array(poses_mat)[:,2,-1]), np.max(np.array(poses_mat)[:,2,-1])])\n",
        "\n",
        "    if datasetname == 'S':\n",
        "        visualizer.ax3d1.view_init(elev=10, azim=80)\n",
        "    elif datasetname == 'B':\n",
        "        visualizer.ax3d1.view_init(elev=-30, azim=30)\n",
        "    else:\n",
        "        visualizer.ax3d1.view_init(elev=10, azim=30)\n",
        "\n",
        "    intrinsics = np.eye(3)\n",
        "    intrinsics[0, 0] = 227.6\n",
        "    intrinsics[0, 2] = 227.6\n",
        "    intrinsics[1, 1] = 237.5\n",
        "    intrinsics[1, 2] = 237.5\n",
        "\n",
        "    for j in range(0, len(poses_mat), 5):\n",
        "        gt = poses_mat[j]\n",
        "        depth0 = np.array(Image.open(data_root +'Frames_'+datasetname + scene + '/Depth_' + str(j).zfill(4) + '.png'))/256/255 * 20\n",
        "\n",
        "        im0 = plt.imread(data_root + 'Frames_'+datasetname + scene + '/FrameBuffer_' + str(j).zfill(4) + '.png')\n",
        "        im0 = im0[:, :, :3].reshape((-1, 3))\n",
        "\n",
        "        cam_coords0 = pixel2cam(torch.tensor(depth0.reshape((1, 475, 475))).float(),\n",
        "                                torch.tensor(intrinsics).inverse().float())\n",
        "        cam_coords_flat0 = cam_coords0.reshape(1, 3, -1).numpy()\n",
        "\n",
        "        rot_gt, tr_gt = gt[:3, :3], gt[:3, -1:]\n",
        "        cloud_gt = rot_gt @ cam_coords_flat0 + tr_gt\n",
        "        indeces = np.random.choice(225625, size=1000, replace=False)\n",
        "\n",
        "        visualizer.ax3d1.scatter(cloud_gt[0, 0, indeces], cloud_gt[0, 1, indeces], cloud_gt[0, 2, indeces],\n",
        "                                 c=im0[indeces, :],\n",
        "                                 s=1)\n",
        "        if j % 20 == 0:\n",
        "            visualizer.extrinsic2pyramidAbs(poses_mat[j], 'b', 0.7)\n",
        "    visualizer.show('pointcloud_' + datasetname + '_' + scene)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    datasetname = 'S'\n",
        "    scene = '7'\n",
        "    data_root = 'data/'\n",
        "    #plot_growing_cloud(datasetname, scene, data_root)\n",
        "    locations = []\n",
        "    rotations = []\n",
        "    loc_reader = open(data_root +'SavedPosition_' + datasetname + scene + '.txt', 'r')\n",
        "    rot_reader = open(data_root +'SavedRotationQuaternion_' + datasetname + scene + '.txt',\n",
        "                      'r')\n",
        "    for line in loc_reader:\n",
        "        locations.append(list(map(float, line.split())))\n",
        "    loc_reader.close\n",
        "\n",
        "    for line in rot_reader:\n",
        "        rotations.append(list(map(float, line.split())))\n",
        "    rot_reader.close\n",
        "\n",
        "    locations = np.array(locations)  # in cm\n",
        "    rotations = np.array(rotations)\n",
        "    poses = np.concatenate([locations, rotations], 1)\n",
        "\n",
        "    r = R.from_quat(rotations).as_matrix()\n",
        "\n",
        "    TM = np.eye(4)\n",
        "    TM[1, 1] = -1\n",
        "\n",
        "    poses_mat = []\n",
        "    for i in range(locations.shape[0]):\n",
        "        ri = r[i]  # np.linalg.inv(r[0])\n",
        "        Pi = np.concatenate((ri, locations[i].reshape((3, 1))), 1)\n",
        "        Pi = np.concatenate((Pi, np.array([0.0, 0.0, 0.0, 1.0]).reshape((1, 4))), 0)\n",
        "        Pi_left = TM @ Pi @ TM\n",
        "        poses_mat.append(Pi_left)\n",
        "\n",
        "    visualizer = CameraPoseVisualizerSlim([np.min(np.array(poses_mat)[:,0,-1]), np.max(np.array(poses_mat)[:,0,-1])],\n",
        "                                          [np.min(np.array(poses_mat)[:,1,-1]), np.max(np.array(poses_mat)[:,1,-1])],\n",
        "                                          [np.min(np.array(poses_mat)[:,2,-1]), np.max(np.array(poses_mat)[:,2,-1])])\n",
        "\n",
        "    if datasetname == 'S':\n",
        "        visualizer.ax3d1.view_init(elev=10, azim=80)\n",
        "    elif datasetname == 'B':\n",
        "        visualizer.ax3d1.view_init(elev=-30, azim=30)\n",
        "    else:\n",
        "        visualizer.ax3d1.view_init(elev=10, azim=30)\n",
        "\n",
        "    intrinsics = np.eye(3)\n",
        "    intrinsics[0, 0] = 227.6\n",
        "    intrinsics[0, 2] = 227.6\n",
        "    intrinsics[1, 1] = 237.5\n",
        "    intrinsics[1, 2] = 237.5\n",
        "    \n",
        "    for j in range(0, len(poses_mat), 5):\n",
        "        gt = poses_mat[j]\n",
        "        depth0 = np.array(Image.open(data_root +'Frames_'+datasetname + scene + '/Depth_' + str(j).zfill(4) + '.png'))/256/255 * 20\n",
        "\n",
        "        im0 = plt.imread(data_root + 'Frames_'+datasetname + scene + '/FrameBuffer_' + str(j).zfill(4) + '.png')\n",
        "        im0 = im0[:, :, :3].reshape((-1, 3))\n",
        "\n",
        "        cam_coords0 = pixel2cam(torch.tensor(depth0.reshape((1, 475, 475))).float(),\n",
        "                                torch.tensor(intrinsics).inverse().float())\n",
        "        cam_coords_flat0 = cam_coords0.reshape(1, 3, -1).numpy()\n",
        "\n",
        "        rot_gt, tr_gt = gt[:3, :3], gt[:3, -1:]\n",
        "        cloud_gt = rot_gt @ cam_coords_flat0 + tr_gt\n",
        "        indeces = np.random.choice(225625, size=1000, replace=False)\n",
        "\n",
        "        visualizer.ax3d1.scatter(cloud_gt[0, 0, indeces], cloud_gt[0, 1, indeces], cloud_gt[0, 2, indeces],\n",
        "                                 c=im0[indeces, :],\n",
        "                                 s=1)\n",
        "        if j % 20 == 0:\n",
        "            visualizer.extrinsic2pyramidAbs(poses_mat[j], 'b', 0.7)\n",
        "        \n",
        "        #if j == 5:\n",
        "            #break\n",
        "    visualizer.show('pointcloud_' + datasetname + '_' + scene)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "gxNdy6i4Kc_H",
        "outputId": "b2b6f41c-6fe1-4064-cd85-f4447cf506a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-16813d97d04e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mposes_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     visualizer = CameraPoseVisualizerSlim([np.min(np.array(poses_mat)[:,0,-1]), np.max(np.array(poses_mat)[:,0,-1])],\n\u001b[0m\u001b[1;32m    135\u001b[0m                                           \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                                           [np.min(np.array(poses_mat)[:,2,-1]), np.max(np.array(poses_mat)[:,2,-1])])\n",
            "\u001b[0;32m<ipython-input-3-8e1517ead724>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xlim, ylim, zlim)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubfigures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max3d1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'subfigures'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}